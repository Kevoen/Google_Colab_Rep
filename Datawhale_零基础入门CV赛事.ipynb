{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Datawhale 零基础入门CV赛事.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1lgBIvOu-kVxbxsX3hqN1_l3bgplf_blB",
      "authorship_tag": "ABX9TyM2PbabQrh3lLRXF4ZqP4+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevoen/Google_Colab_Rep/blob/master/Datawhale_%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8CV%E8%B5%9B%E4%BA%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yLsg1erotc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23b92978-c2d9-4c99-e225-0294330defad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XPCLXDuxysY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "63f2b281-6a8c-4a38-a829-a479a5456969"
      },
      "source": [
        "!ln -s /content/drive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'0720掌控习惯 .gdoc'\t\t  images\t    网络\n",
            " Colab_Notebooks\t\t  obj.data\t    网络转存文件夹\n",
            " Colad_Notebooks\t\t  ProjectFiles\t    资源\n",
            " Deep-Learning-with-PyTorch.pdf   Share-2020Books\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk_07TuLzckf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 显示\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "\n",
        "# 上传文件\n",
        "def upload():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload() \n",
        "  for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "      f.write(data)\n",
        "      print ('saved file', name)\n",
        "\n",
        "# 下载文件 \n",
        "def download(path):\n",
        "  from google.colab import files\n",
        "  files.download(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGoiVWb-18oX",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "66a75efc-a3d2-48b2-e775-ac9eea6be905"
      },
      "source": [
        "upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c52f42c8-3fa4-4b20-8d60-547a8c79934a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c52f42c8-3fa4-4b20-8d60-547a8c79934a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mchar_data_list_0515.csv to mchar_data_list_0515.csv\n",
            "saved file mchar_data_list_0515.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIbCxtxV2AWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#读取数据\n",
        "import pandas as pd\n",
        "data_list = pd.read_csv(\"/content/mchar_data_list_0515.csv\")\n",
        "data_list.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0BTxtC9ve4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f692bf7b-0ba5-4dd1-82a7-d39b884fd63d"
      },
      "source": [
        "data_list['link']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    http://tianchi-competition.oss-cn-hangzhou.ali...\n",
              "1    http://tianchi-competition.oss-cn-hangzhou.ali...\n",
              "2    http://tianchi-competition.oss-cn-hangzhou.ali...\n",
              "3    http://tianchi-competition.oss-cn-hangzhou.ali...\n",
              "4    http://tianchi-competition.oss-cn-hangzhou.ali...\n",
              "5    http://tianchi-competition.oss-cn-hangzhou.ali...\n",
              "Name: link, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdSZ4b2-SN5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec2b56dd-2668-42d4-8ba3-fa6f22798ac2"
      },
      "source": [
        "%cd /content/\n",
        "%cd ../mydrive/Colab_Notebooks/TianChi/"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/My Drive/Colab_Notebooks/TianChi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4gukukQ91Hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531795/mchar_train.zip\n",
        "!wget http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531795/mchar_train.json\n",
        "!wget http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531795/mchar_val.zip\n",
        "!wget http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531795/mchar_val.json\n",
        "!wget http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531795/mchar_test_a.zip\n",
        "!wget http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531795/mchar_sample_submit_A.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phNfukiH-H_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d8939e95-88e6-43d0-c7e3-6d350b1b7953"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Datawhale 零基础入门CV赛事.ipynb'   mchar_test_a.zip   \u001b[0m\u001b[01;34mmchar_val\u001b[0m/\n",
            " \u001b[01;34m__MACOSX\u001b[0m/                           \u001b[01;34mmchar_train\u001b[0m/       mchar_val.json\n",
            " mchar_sample_submit_A.csv           mchar_train.json   mchar_val.zip\n",
            " \u001b[01;34mmchar_test_a\u001b[0m/                       mchar_train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je017KdfVCpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -d ./mchar/train/ mchar_train.zip\n",
        "#!unzip mchar_train.zip\n",
        "#!unzip mchar_val.zip\n",
        "!unzip mchar_test_a.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k6SX4RdVK2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecaa2073-ae62-4635-d76a-8c0efebedbbc"
      },
      "source": [
        "import os, sys, glob, shutil, json\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "%pylab inline\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = False\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.dataset import Dataset"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbxScpDGTnOG",
        "colab_type": "text"
      },
      "source": [
        "## 定义数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgnMXQQH5geE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SVHNDataset(Dataset):\n",
        "\n",
        "  def __init__(self, img_path, img_label, transform=None):  #初始化函数 内部参数初始化\n",
        "    self.img_path = img_path\n",
        "    self.img_label = img_label\n",
        "    if transform is not None:\n",
        "      self.transform = transform\n",
        "    else:\n",
        "      self.transform = None\n",
        "  \n",
        "  def __getitem__(self, index):          #获取Dataset数据\n",
        "    img = cv2.imread(self.img_path[index])    #使用opencv读取图像\n",
        "    img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    #cv2.cvtColor()函数返回的是一个img数组，后面需要Image类；\n",
        "    #img = Image.open(self.img_path[index]).convert('RGB')\n",
        "    if self.transform is not None:\n",
        "      img = self.transform(img)\n",
        "\n",
        "    lbl = self.img_label[index]   \n",
        "    lbl = lbl + (5 - len(lbl)) * [10]   #定长字符填充\n",
        "\n",
        "    # 原始SVHN中类别10为数字0\n",
        "    #lbl = np.array(self.img_label[index], dtype=np.int)\n",
        "    #lbl = list(lbl)  + (5 - len(lbl)) * [10]\n",
        "\n",
        "    return img, torch.from_numpy(np.array(lbl[:5]))  #使用torch.from_numpy()将numpy转换成张量\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_path)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW7xv9JiUL6I",
        "colab_type": "text"
      },
      "source": [
        "## 定义训练数据和验证数据的Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOjiFwgbYmWn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4b222e3f-548b-4000-fedc-23d48d743fc3"
      },
      "source": [
        "train_path = glob.glob('./mchar_train/*.png') #加载train data路径\n",
        "train_path.sort()\n",
        "train_json = json.load(open('./mchar_train.json'))#加载标签json\n",
        "train_label = [train_json[x]['label'] for x in train_json]#加载便签\n",
        "print(\"train_path:\",len(train_path),\"train_label:\",len(train_label))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(      #设置Pytorch的Dataset数据加载器\n",
        "    SVHNDataset(train_path, train_label,\n",
        "                transforms.Compose([\n",
        "                  transforms.Resize((64, 120)),   #缩放到固定大小\n",
        "                  transforms.RandomCrop((60, 120)),   #切割中心点的位置随机选取\n",
        "                  transforms.ColorJitter(0.3, 0.3, 0.2), #随机颜色变换\n",
        "                  transforms.RandomRotation(10),    #随机旋转\n",
        "                  transforms.ToTensor(),     # 将图片转换为pytorch的tesntor\n",
        "                  transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) # 对图像像素进行归一化                   \n",
        "                ])),\n",
        "    batch_size = 50,\n",
        "    shuffle = True,\n",
        "    num_workers = 10\n",
        ")\n",
        "\n",
        "val_path = glob.glob('./mchar_val/*.png')\n",
        "val_path.sort()\n",
        "val_json = json.load(open('./mchar_val.json'))\n",
        "val_label = [val_json[x]['label'] for x in val_json]\n",
        "print(\"val_path:\",len(val_path),\"val_label:\",len(val_label))\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    SVHNDataset(val_path, val_label,\n",
        "                transforms.Compose([\n",
        "                  transforms.Resize((64, 120)),\n",
        "                  # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
        "                  # transforms.RandomRotation(10),\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])                    \n",
        "                ])),\n",
        "    batch_size = 50,\n",
        "    shuffle = False,\n",
        "    num_workers = 10                               \n",
        ")\n",
        "\n",
        "# for data in train_loder:\n",
        "#   break\n",
        "\n",
        "#[img, label] = data\n",
        "# print(img.size(), label.size())\n",
        "#print(label)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_path: 30000 train_label: 30000\n",
            "val_path: 10000 val_label: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAWdvrPo4uOi",
        "colab_type": "text"
      },
      "source": [
        "构建模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1DLXJ4zWwTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SVHN_Model1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SVHN_Model1, self).__init__()\n",
        "    #CNN提取特征模块\n",
        "\n",
        "    model_conv = models.resnet18(pretrained=True)\n",
        "    model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "    model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
        "    self.cnn = model_conv\n",
        "\n",
        "    self.fc1 = nn.Linear(512, 11)\n",
        "    self.fc2 = nn.Linear(512, 11)\n",
        "    self.fc3 = nn.Linear(512, 11)\n",
        "    self.fc4 = nn.Linear(512, 11)\n",
        "    self.fc5 = nn.Linear(512, 11)\n",
        "\n",
        "  def forward(self, img):\n",
        "    feat = self.cnn(img)\n",
        "    # print(feat.shape)\n",
        "    feat = feat.view(feat.shape[0], -1)\n",
        "    c1 = self.fc1(feat)\n",
        "    c2 = self.fc2(feat)\n",
        "    c3 = self.fc3(feat)\n",
        "    c4 = self.fc4(feat)\n",
        "    c5 = self.fc5(feat)\n",
        "    return c1,c2,c3,c4,c5"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZcX0EHHFLxc",
        "colab_type": "text"
      },
      "source": [
        "## 每个Epoch的训练、验证、测试代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YDBc7yOEYQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    # 切换模型为训练模式\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    \n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        if use_cuda:\n",
        "            input = input.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        c0, c1, c2, c3, c4 = model(input)\n",
        "        loss = criterion(c0, target[:, 0]) + \\\n",
        "                criterion(c1, target[:, 1]) + \\\n",
        "                criterion(c2, target[:, 2]) + \\\n",
        "                criterion(c3, target[:, 3]) + \\\n",
        "                criterion(c4, target[:, 4])\n",
        "        \n",
        "        # loss /= 6\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss.append(loss.item())\n",
        "    return np.mean(train_loss)\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    # 切换模型为预测模型\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "\n",
        "    # 不记录模型梯度信息\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            if use_cuda:\n",
        "                input = input.cuda()\n",
        "                target = target.cuda()\n",
        "            \n",
        "            c0, c1, c2, c3, c4 = model(input)\n",
        "            loss = criterion(c0, target[:, 0]) + \\\n",
        "                    criterion(c1, target[:, 1]) + \\\n",
        "                    criterion(c2, target[:, 2]) + \\\n",
        "                    criterion(c3, target[:, 3]) + \\\n",
        "                    criterion(c4, target[:, 4])\n",
        "            # loss /= 6\n",
        "            val_loss.append(loss.item())\n",
        "    return np.mean(val_loss)\n",
        "\n",
        "def predict(test_loader, model, tta=10):\n",
        "    model.eval()\n",
        "    test_pred_tta = None\n",
        "    \n",
        "    # TTA 次数\n",
        "    for _ in range(tta):\n",
        "        test_pred = []\n",
        "    \n",
        "        with torch.no_grad():\n",
        "            for i, (input, target) in enumerate(test_loader):\n",
        "                if use_cuda:\n",
        "                    input = input.cuda()\n",
        "                \n",
        "                c0, c1, c2, c3, c4 = model(input)\n",
        "                if use_cuda:\n",
        "                    output = np.concatenate([\n",
        "                        c0.data.cpu().numpy(), \n",
        "                        c1.data.cpu().numpy(),\n",
        "                        c2.data.cpu().numpy(), \n",
        "                        c3.data.cpu().numpy(),\n",
        "                        c4.data.cpu().numpy()], axis=1)\n",
        "                else:\n",
        "                    output = np.concatenate([\n",
        "                        c0.data.numpy(), \n",
        "                        c1.data.numpy(),\n",
        "                        c2.data.numpy(), \n",
        "                        c3.data.numpy(),\n",
        "                        c4.data.numpy()], axis=1)\n",
        "                \n",
        "                test_pred.append(output)\n",
        "        \n",
        "        test_pred = np.vstack(test_pred)\n",
        "        if test_pred_tta is None:\n",
        "            test_pred_tta = test_pred\n",
        "        else:\n",
        "            test_pred_tta += test_pred\n",
        "    \n",
        "    return test_pred_tta"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC-HqvueHI1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "47fc6e65-f3a3-4c81-e145-10a10b06a440"
      },
      "source": [
        "model = SVHN_Model1()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "best_loss = 1000.0\n",
        "lr = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)  #优化器，Adam自适应调整学习率\n",
        "# 是否使用GPU\n",
        "use_cuda = True\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "for epoch in range(20):\n",
        "    \n",
        "    train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
        "    val_loss = validate(val_loader, model, criterion)\n",
        "    \n",
        "    val_label = [''.join(map(str, x)) for x in val_loader.dataset.img_label]\n",
        "    val_predict_label = predict(val_loader, model, 1)\n",
        "    val_predict_label = np.vstack([\n",
        "        val_predict_label[:, :11].argmax(1),\n",
        "        val_predict_label[:, 11:22].argmax(1),\n",
        "        val_predict_label[:, 22:33].argmax(1),\n",
        "        val_predict_label[:, 33:44].argmax(1),\n",
        "        val_predict_label[:, 44:55].argmax(1),\n",
        "    ]).T\n",
        "    val_label_pred = []\n",
        "    for x in val_predict_label:\n",
        "        val_label_pred.append(''.join(map(str, x[x!=10])))\n",
        "    \n",
        "    val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n",
        "    \n",
        "    print('Epoch: {0}, Train loss: {1} \\t Val loss: {2} \\t Val Acc: {3}'.format(epoch, train_loss, val_loss, val_char_acc))\n",
        "    # print('Val Acc', val_char_acc)\n",
        "    # 记录下验证集精度\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        # print('Find better model in Epoch {0}, saving model.'.format(epoch))\n",
        "        torch.save(model.state_dict(), './model.pt')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Train loss: 3.570577224691709 \t Val loss: 3.467509013414383 \t Val Acc: 0.3503\n",
            "Epoch: 1, Train loss: 2.236784227887789 \t Val loss: 3.0147114324569704 \t Val Acc: 0.4339\n",
            "Epoch: 2, Train loss: 1.8742641349633535 \t Val loss: 2.8130609297752383 \t Val Acc: 0.4647\n",
            "Epoch: 3, Train loss: 1.6511709041396776 \t Val loss: 2.8379648435115814 \t Val Acc: 0.462\n",
            "Epoch: 4, Train loss: 1.482074794570605 \t Val loss: 2.7579031616449354 \t Val Acc: 0.49\n",
            "Epoch: 5, Train loss: 1.3397448036074637 \t Val loss: 2.5652968788146975 \t Val Acc: 0.5117\n",
            "Epoch: 6, Train loss: 1.2293370397885641 \t Val loss: 2.603809491991997 \t Val Acc: 0.5074\n",
            "Epoch: 7, Train loss: 1.1353463484346866 \t Val loss: 2.780683387517929 \t Val Acc: 0.505\n",
            "Epoch: 8, Train loss: 1.05139728029569 \t Val loss: 2.6150356978178024 \t Val Acc: 0.5407\n",
            "Epoch: 9, Train loss: 0.9564973652859529 \t Val loss: 2.760325657129288 \t Val Acc: 0.5288\n",
            "Epoch: 10, Train loss: 0.889187194382151 \t Val loss: 2.8139515709877014 \t Val Acc: 0.5343\n",
            "Epoch: 11, Train loss: 0.8053533612688383 \t Val loss: 2.853030298948288 \t Val Acc: 0.5367\n",
            "Epoch: 12, Train loss: 0.7494235488275687 \t Val loss: 2.8924017894268035 \t Val Acc: 0.5335\n",
            "Epoch: 13, Train loss: 0.6795009421805541 \t Val loss: 2.9356063228845595 \t Val Acc: 0.5367\n",
            "Epoch: 14, Train loss: 0.6194405573854844 \t Val loss: 3.0431115013360976 \t Val Acc: 0.5374\n",
            "Epoch: 15, Train loss: 0.5492379956940809 \t Val loss: 3.4680871897935868 \t Val Acc: 0.5184\n",
            "Epoch: 16, Train loss: 0.5123735995839039 \t Val loss: 3.5267603117227555 \t Val Acc: 0.517\n",
            "Epoch: 17, Train loss: 0.462354248650372 \t Val loss: 3.5092296302318573 \t Val Acc: 0.5362\n",
            "Epoch: 18, Train loss: 0.42191190699115394 \t Val loss: 3.534285923242569 \t Val Acc: 0.5381\n",
            "Epoch: 19, Train loss: 0.38589626516525943 \t Val loss: 3.565106621980667 \t Val Acc: 0.529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzTcRAXCQc6Q",
        "colab_type": "text"
      },
      "source": [
        "## 预测并生成提交文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GutPjHklQhh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_path = glob.glob('./mchar_test/*.png')\n",
        "test_path.sort()\n",
        "test_label = [[1]] * len(test_path)\n",
        "print(len(test_path), len(test_label))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    SVHNDataset(test_path, test_label,\n",
        "          transforms.Compose([\n",
        "            transforms.Resize((60, 120)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])),\n",
        "    batch_size=40,\n",
        "    shuffle=False,\n",
        "    num_workers=10,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN3wB6E7Q1bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 加载保存的最优模型生成提交文件\n",
        "model.load_state_dict(torch.load('model.pt'))\n",
        "\n",
        "test_predict_label = predict(test_loader, model, 1)\n",
        "print(test_predict_label.shape)\n",
        "\n",
        "test_label = [''.join(map(str, x)) for x in test_loader.dataset.img_label]\n",
        "test_predict_label = np.vstack([\n",
        "    test_predict_label[:, :11].argmax(1),\n",
        "    test_predict_label[:, 11:22].argmax(1),\n",
        "    test_predict_label[:, 22:33].argmax(1),\n",
        "    test_predict_label[:, 33:44].argmax(1),\n",
        "    test_predict_label[:, 44:55].argmax(1),\n",
        "]).T\n",
        "\n",
        "test_label_pred = []\n",
        "for x in test_predict_label:\n",
        "    test_label_pred.append(''.join(map(str, x[x!=10])))\n",
        "\n",
        "import pandas as pd\n",
        "df_submit = pd.read_csv('../../../dataset/tianchi_SVHN/test_A_sample_submit.csv')\n",
        "df_submit['file_code'] = test_label_pred\n",
        "df_submit.to_csv('submit.csv', index=None)  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}